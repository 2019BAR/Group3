---
title: UNIT12A：邏輯式性回歸 Logistic Regression
author: 第三組 王欣 黃柏勳 劉漢慈 王誠歆 張延瑋 李燦宇 孫嘉力
date: "`r Sys.time()`"
output: 
  html_document:
    highlight: pygments
    theme: flatly
    css: style_hsin.css
---

```{r results='hide', message=FALSE, warning=FALSE, echo=F}
# Formating Codes.  Do not change the codes in this chunk !!
rm(list=ls(all=T))
knitr::opts_chunk$set(comment = NA)
knitr::opts_knit$set(global.par = TRUE)
par(cex=0.8)
options(scipen=20, digits=5, width=80)
if(!require(pacman)) install.packages("pacman")
```
<hr>

```{r results='hide', message=FALSE, warning=FALSE}
pacman::p_load(ggplot2, dplyr)
```
<hr>

### 【A】簡單案例

+ 資料：Binary Target Variable

```{r}
D = read.csv("data/quality.csv")  # Read in dataset
D = D[,c(14, 4, 5)]
names(D) = c("y", "x1", "x2")
table(D$y)
```

+ 方法：`glm(, family=binomial)` Generalize Liner Model

```{r}
glm1 = glm(y~x1+x2, D, family=binomial)
summary(glm1)
```

```{r}
b = coef(glm1); b   # extract the regression coef
```

+ $logit = f(x) = b_0 + b_1 x_1 + b_2 x_2$

+ $odd = Exp(logit)$

+ $Pr[y = 1] = prob = \frac{odd}{1+odd}$

Given `x1=3, x2=4`, what are the predicted logit, odd and probability?
```{r}
logit = sum(b * c(1, 3, 4))
odd = exp(logit)
prob = odd/(1+odd)
c(logit=logit, odd=odd, prob=prob)
```

<span style="font-size:24px"> `r "\U1F5FF"` : </span>
What if `x1=2, x2=3`?

<span style="font-size:24px"> `r "\U1F4A1"` : </span>**if `x1=2, x2=3`**
```{r}
logit = sum(b * c(1, 2, 3))
odd = exp(logit)
prob = odd/(1+odd)
c(logit=logit, odd=odd, prob=prob)
```
<br>

<span style="font-size:24px"> `r "\U1F4A1"` : </span>
`glm(family=binomial)`的功能：在 $\{x\}$ 的空間之中，找出區隔 $y$ 的(類別)界線

We can plot the line of `logit = 0` or `odd = 1, prob = 0.5` on the plane of $X$
```{r fig.width=3.6, fig.height=3.6}
par(cex=0.8, mar=c(4,4,1,1))
plot(D$x1, D$x2, col=2+D$y, pch=20, cex=1.2, xlab="X1", ylab="X2")
abline(-b[1]/b[3], -b[2]/b[3], col="blue", lty=3)
```

Furthermore, we can translate probability, logit and coefficents to intercept & slope ...

$$f(x) = b_0 + b_1 x_1 + b_2 x_2 \; \Rightarrow \;  x_2 = \frac{f - b_0}{b_2} - \frac{b_1}{b_2}x_1$$

```{r  fig.width=3.6, fig.height=3.6}
p = seq(0.1,0.9,0.1)
logit = log(p/(1-p))
data.frame(prob = p, logit)
```

then mark the contours of proabilities into the scatter plot 
```{r  fig.width=5, fig.height=5, fig.align='center'}
par(cex=0.8, mar=c(4,4,1,1))
plot(D$x1, D$x2, col=2+D$y,
     pch=20, cex=1.3, xlab='X1', ylab='X2')
for(f in logit) {
  abline((f-b[1])/b[3], -b[2]/b[3], col=ifelse(f==0,'blue','cyan')) }
#加數值標示
text(1,3.5,"0.1",col = "#4592af",cex = 1.5)
text(1,11,"0.2",col = "#4592af",cex = 1.5)
text(1,15.5,"0.3",col = "#4592af",cex = 1.5)
text(1,19.5,"0.4",col = "#4592af",cex = 1.5)
text(1,23.5,"0.5",col = "#010059",cex = 1.5)
text(1,27.5,"0.6",col = "#4592af",cex = 1.5)
text(1,31.5,"0.7",col = "#4592af",cex = 1.5)
text(1,36.5,"0.8",col = "#4592af",cex = 1.5)
text(1,43.5,"0.9",col = "#4592af",cex = 1.5)
#加舉例
text(25.3,35.5,"0.95",col = "red",cex = 1)
text(13,31.5,"0.82",col = "#0b8457",cex = 1)
```

<span style="font-size:24px"> `r "\U1F5FF"` : </span>
What do the blue/cyan lines means?<br>

+ **分別代表在預測機率p(y=1)=0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9的等值線**
(如上圖標示)


<span style="font-size:24px"> `r "\U1F5FF"` : </span>
Given any point in the figure above, how can you tell its (predicted) probability approximately?<br>

+ **可以根據該點(X1,X2)的位置和某一條估計線的垂直距離來判斷p(y=1)的機率**
+ **如圖所示，以綠點及紅點各一例，我們分別猜測：紅點向上遠離0.9的機率線大約為0.95；綠點介於0.8-0.9之間且更接近0.8的機率線，故猜測約為0.82**

<br><hr>

### 【B】 邏輯式回歸

##### 機率、勝率(Odd)、Logit

+ Odd =  $p/(1-p)$

+ Logit = $log(odd)$ = $log(\frac{p}{1=p})$

+ $o = p/(1-p)$ ; $p = o/(1+o)$ ;  $logit = log(o)$

```{r fig.height=3.6, fig.width=7}
par(cex=0.8, mfcol=c(1,2))
curve(x/(1-x), 0.02, 0.98, col='cyan',lwd=2, 
    ylab='odd', xlab='p')
abline(v=seq(0,1,0.1), h=seq(0,50,5), col='lightgray', lty=3)
curve(log(x/(1-x)), 0.005, 0.995, lwd=2, col='purple', 
      ylab="logit",xlab='p')
abline(v=seq(0,1,0.1), h=seq(-5,5,1), col='lightgray', lty=3)
```
<br>

##### Logistic Function & Logistic Regression

+ Linear Model: $y = f(x) = b_0 + b_1x_1 + b_2x_2 + ...$

+ General Linear Model(GLM): $y = Link(f(x))$ 

+ Logistic Regression: $logit(y) = log(\frac{p}{1-p}) = f(x) \text{ where } p = prob[y=1]$ 

+ Logistic Function: $Logistic(F_x) = \frac{1}{1+Exp(-F_x)} = \frac{Exp(F_x)}{1+Exp(F_x)}$

```{r  fig.width=6, fig.height=3.6}
par(cex=0.8, mfrow=c(1,1))
curve(1/(1+exp(-x)), -5, 5, col='blue', lwd=2,main="Logistic Function",
      xlab="f(x): the logit of y = 1", ylab="the probability of y = 1")
abline(v=-5:5, h=seq(0,1,0.1), col='lightgray', lty=2)
abline(v=0,h=0.5,col='pink')
points(0,0.5,pch=20,cex=1.5,col='red')
```

<span style="font-size:24px"> `r "\U1F5FF"` : </span>
What are the definiion of `logit` & `logistic function`? What is the relationship between them?<br>

+ **假設我們現在定義一件事情的成功機率p，那麼`odd則為p/(1-p)`,而`logit=log(odd) = log(p/(1-p))`，這一系列過程就稱之為logit轉換。**
+ **Logistic Function是為一種activation function,作用是把線性函數的值域從實數區間"擠壓"到(0,1)之間，可以用來表示機率。**
+ **Logit和Logistic Function基本上都為一種數學式。**
    + **前者是一種機率的概念，將勝率(odd)取log的計算結果。**
    + **後者是將Logit的值再代入Logistic Function函數轉換，進一步得出所估計出的機率。**
+ **所以我們可以說明兩者之間的關係是Logit為Logistic Function的輸入值。**

<span style="font-size:24px"> `r "\U1F4A1"` : </span>
 **假設今天只有一個自變數x，**<br><br>

&emsp;&emsp;&emsp;&emsp; $f(x) = b_0 + b_1x_1 = logit(odd) = log(\frac{p}{1-p})$ <br><br>
(logit模型設定**對數勝算`log(odd)`**與**解釋變數X**之間呈現線性關係)<br><br>

+ **兩邊同時做指數運算後**<br><br>
&emsp;&emsp;&emsp;$\frac{p}{(1-p)}=Exp(b_0+b_1x)$<br><br>
+ **稍作整理過後**<br><br>
&emsp;&emsp;&emsp;$p=\frac{1}{1+Exp(-(b0+b1x))}$
&emsp;**，即得出logistic function**

+ 總結兩邊式子差異
    + **Logistic Regression的左式是Logit(odd的對數)，右式是一个線性結構。**
    + **Logistic Function的左式是機率，右式是非線性的函數結構。**

<span style="font-size:18px"> &emsp;&emsp; <font color="#913535">`r "\U2764"`最重要的是兩者可以互相轉換`r "\U2764"`</font></span>


<br><br><br><hr>



